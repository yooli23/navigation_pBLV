# Navigation Task Dataset for pBLV on Vision-Language Models

This repository hosts a dataset specifically designed to evaluate the navigation capabilities of Vision-Language Models for assisting people with blindness and low vision (pBLV). The dataset is tailored to test various aspects of navigation tasks, including:

- **Counting**: Evaluating models' ability to count objects accurately in complex scenes.
- **Spatial Reasoning**: Testing relative spatial reasoning in various configurations.
- **Commonsense Reasoning**: Assessing understanding of object interactions and implicit context in navigation scenarios.


The dataset will be uploaded soon.
